{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dace9ed9-84ea-43e6-8203-9129d136f595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_IMAGE = \"pytorch/pytorch:2.3.1-cuda12.1-cudnn8-runtime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b3de6bd2-789f-4ccf-bf15-ee01dc4a95de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.dsl import Input, Output\n",
    "from kfp.dsl import Dataset, Artifact\n",
    "from kfp.dsl import Model, Metrics, ClassificationMetrics\n",
    "\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "841d752a-a222-460e-a76c-86233f0a129d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=BASE_IMAGE,\n",
    ")\n",
    "def load_mnist_data(\n",
    "    train_images_pickle: Output[Dataset],\n",
    "    train_labels_pickle: Output[Dataset],\n",
    "    test_images_pickle: Output[Dataset],\n",
    "    test_labels_pickle: Output[Dataset],\n",
    "):\n",
    "    # import dataset\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    \n",
    "    \n",
    "    # load dataset    \n",
    "    subset_indices = list(range(1000))\n",
    "    train_set = torch.utils.data.Subset(torchvision.datasets.MNIST('.', \n",
    "                        train=True, download=True),subset_indices)\n",
    "    subset_indices = list(range(100))\n",
    "    test_set = torch.utils.data.Subset(torchvision.datasets.MNIST('.', \n",
    "                        train=False, download=True),subset_indices)\n",
    "    print(\"MNIST dataset has been downloaded\")\n",
    "    train_images = [img for img, label in train_set]\n",
    "    train_labels = [label for img, label in train_set]\n",
    "    test_images = [img for img, label in test_set]\n",
    "    test_labels = [label for img, label in test_set]\n",
    "    \n",
    "    print(\"MNIST dataset has been separated\")    \n",
    "  \n",
    "        # Save the data using pickle\n",
    "    with open(train_images_pickle.path, 'wb') as f:\n",
    "        pickle.dump(train_images, f)\n",
    "    with open(train_labels_pickle.path, 'wb') as f:\n",
    "        pickle.dump(train_labels, f)\n",
    "    with open(test_images_pickle.path, 'wb') as f:\n",
    "        pickle.dump(test_images, f)\n",
    "    with open(test_labels_pickle.path, 'wb') as f:\n",
    "         pickle.dump(test_labels, f)        \n",
    "\n",
    "    print(\"MNIST dataset has been pickled.\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3ef6a86a-cb8d-41e5-83c6-7e89c05a8f87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(base_image=BASE_IMAGE)\n",
    "def preprocess_data(\n",
    "    train_images_pickle: Input[Dataset],\n",
    "    train_labels_pickle: Input[Dataset],\n",
    "    test_images_pickle: Input[Dataset],\n",
    "    test_labels_pickle: Input[Dataset],\n",
    "    train_images_prep: Output[Dataset],\n",
    "    train_labels_prep: Output[Dataset],\n",
    "    test_images_prep: Output[Dataset],\n",
    "    test_labels_prep: Output[Dataset],\n",
    "    \n",
    ") -> NamedTuple(\"outputs\", input_size=int, num_labels=int):\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from typing import NamedTuple\n",
    "\n",
    "    with open(train_images_pickle.path, \"rb\") as file:\n",
    "        train_images = pickle.load(file)\n",
    "        \n",
    "    with open(train_labels_pickle.path, \"rb\") as file:\n",
    "        train_labels = pickle.load(file)\n",
    "    \n",
    "    with open(test_images_pickle.path, \"rb\") as file:\n",
    "        test_images= pickle.load(file)\n",
    "        \n",
    "    with open(test_labels_pickle.path, \"rb\") as file:\n",
    "        test_labels= pickle.load(file)\n",
    "\n",
    "    input_size = len(train_images)\n",
    "    num_labels = len(train_labels)\n",
    "#     num_labels = len(np.unique(y_train))\n",
    "\n",
    "#     y_train = to_categorical(y_train)\n",
    "#     y_test = to_categorical(y_test)\n",
    "#     image_size = x_train.shape[1]\n",
    "#     input_size = image_size * image_size\n",
    "#     # resize and normalize\n",
    "#     x_train = np.reshape(x_train, [-1, input_size])\n",
    "#     x_train = x_train.astype(\"float32\") / 255\n",
    "#     x_test = np.reshape(x_test, [-1, input_size])\n",
    "#     x_test = x_test.astype(\"float32\") / 255\n",
    "    with open(train_images_prep.path, \"wb\") as file:\n",
    "        pickle.dump(train_images, file)\n",
    "\n",
    "    with open(train_labels_prep.path, \"wb\") as file:\n",
    "        pickle.dump(train_labels, file)\n",
    "\n",
    "    with open(test_images_prep.path, \"wb\") as file:\n",
    "        pickle.dump(test_images, file)\n",
    "\n",
    "    with open(test_labels_prep.path, \"wb\") as file:\n",
    "        pickle.dump(test_labels, file)\n",
    "        \n",
    "    outputs = NamedTuple(\"outputs\", input_size=int, num_labels=int)\n",
    "    return outputs(input_size, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6cd53b86-c71a-4308-93fc-08966d34b96b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(base_image=BASE_IMAGE)\n",
    "def train(\n",
    "    input_size: int,\n",
    "    num_labels: int,\n",
    "    epochs: int,\n",
    "    train_images_prep: Input[Dataset],\n",
    "    train_labels_prep: Input[Dataset],\n",
    "    model_artifact: Output[Model],\n",
    "    log: Output[Artifact],\n",
    "):\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    import torch.optim as optim    \n",
    "    import pickle\n",
    "    from datetime import datetime\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "            self.conv2_drop = nn.Dropout2d()\n",
    "            self.fc1 = nn.Linear(320, 50)\n",
    "            self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "            x = x.view(-1, 320)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.fc2(x)\n",
    "            return F.log_softmax(x)     \n",
    "    \n",
    "\n",
    "    batch_size_train = 100\n",
    "    batch_size_test = 100\n",
    "    learning_rate = 0.01\n",
    "    momentum = 0.5\n",
    "    log_interval = 10\n",
    "    epochs = 1\n",
    "\n",
    "    random_seed = 1\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    with open(train_images_prep.path, \"rb\") as file:\n",
    "        train_images = pickle.load(file)\n",
    "\n",
    "    with open(train_labels_prep.path, \"rb\") as file:\n",
    "        train_labels = pickle.load(file)\n",
    "\n",
    "    log_dir = f\"{log.path}/logs/fit/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Running on {device}.\")\n",
    "    network = Net()\n",
    "    optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)    \n",
    "    # transform=torchvision.transforms.Compose([\n",
    "    #     torchvision.transforms.ToTensor(),\n",
    "    #     torchvision.transforms.Normalize(\n",
    "    #                  (0.1307,), (0.3081,))])    \n",
    "    train_losses = []\n",
    "    train_counter = []\n",
    "    test_losses = []\n",
    "    test_counter = [i* input_size for i in range(epochs + 1)]   \n",
    "    #transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((28,28)),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])    \n",
    "    print(\"started training\")\n",
    "    network.train()\n",
    "    \n",
    "#    for epoch in range(1, epochs + 1):\n",
    "    for data, target in zip(train_images, train_labels):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, transform(target))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), input_size,\n",
    "            100. * batch_idx / input_size, loss.item()))\n",
    "          train_losses.append(loss.item())\n",
    "          train_counter.append(\n",
    "            (batch_idx*64) + ((epoch-1)*input_size))\n",
    "          torch.save(network.state_dict(), model_artifact.path + '/model.pth')\n",
    "          torch.save(optimizer.state_dict(), model_artifact.path + '/optimizer.pth')    \n",
    "\n",
    "    print(\"finished training\")\n",
    "\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f024658d-6560-4aca-9608-396c6428b10b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    packages_to_install=[\"scikit-learn\"],\n",
    ")\n",
    "def evaluate(\n",
    "    model_artifact: Input[Model],\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    scalar_metrics: Output[Metrics],\n",
    "    test_images_prep: Input[Dataset],\n",
    "    test_labels_prep: Input[Dataset],\n",
    "):\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    import torch.optim as optim    \n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "            self.conv2_drop = nn.Dropout2d()\n",
    "            self.fc1 = nn.Linear(320, 50)\n",
    "            self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "            x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "            x = x.view(-1, 320)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.fc2(x)\n",
    "            return F.log_softmax(x)     \n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Running on {device}.\")    \n",
    "    \n",
    "    with open(test_images_prep.path, \"rb\") as file:\n",
    "        test_images = pickle.load(file)\n",
    "\n",
    "    with open(test_labels_prep.path, \"rb\") as file:\n",
    "        test_labels = pickle.load(file)  \n",
    "  \n",
    "         \n",
    "    \n",
    "\n",
    "    network = model.load_state_dict(torch.load(model_artifact.path + '/model.pth', weights_only=True))\n",
    "\n",
    "    # Set the model to evaluation mode. This is important as certain layers like dropout behave differently during training and evaluation.\n",
    "    network.eval()\n",
    "\n",
    "    # Lists to store all predictions and true labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    # Define the class labels for the Fashion MNIST dataset.\n",
    "    classes = ('zero','one','two','three','four','five','six','seven','eight','nine')\n",
    "\n",
    "    # We don't want to compute gradients during evaluation, hence wrap the code inside torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        # Iterate over all batches in the test loader\n",
    "        for images, labels in zip(test_images, test_labels):        \n",
    "            # Transfer images and labels to the computational device (either CPU or GPU)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Pass the images through the model to get predictions\n",
    "            outputs = network(images)\n",
    "\n",
    "            # Get the class with the maximum probability as the predicted class\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Extend the all_preds list with predictions from this batch\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Extend the all_labels list with true labels from this batch\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Print a classification report which provides an overview of the model's performance for each class\n",
    "    print(classification_report(all_labels, all_preds, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "46696c0c-6cfc-4ed8-b6eb-59a832aa89b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/de3c2f0e-236a-429e-b8cc-521fb6239df1\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/8b1b0c14-7af9-450f-a2a1-97e9b2a800a6\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=8b1b0c14-7af9-450f-a2a1-97e9b2a800a6)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"pytorch_mnist_pipeline_v3\",\n",
    ")\n",
    "def pytorch_mnist_pipeline_v3(epochs: int):\n",
    "    data = (\n",
    "        load_mnist_data()\n",
    "        .set_memory_limit(\"4G\")\n",
    "        .set_memory_request(\"2G\")\n",
    "        .set_cpu_limit(\"2\")\n",
    "        .set_cpu_request(\"1\")\n",
    "    )\n",
    "    preprocess = (\n",
    "        preprocess_data(\n",
    "            train_images_pickle=data.outputs[\"train_images_pickle\"],\n",
    "            train_labels_pickle=data.outputs[\"train_labels_pickle\"],\n",
    "            test_images_pickle=data.outputs[\"test_images_pickle\"],\n",
    "            test_labels_pickle=data.outputs[\"test_labels_pickle\"],\n",
    "        )\n",
    "        .set_memory_limit(\"4G\")\n",
    "        .set_memory_request(\"4G\")\n",
    "        .set_cpu_limit(\"1\")\n",
    "        .set_cpu_request(\"1\")\n",
    "    )\n",
    "    preprocess.after(data)\n",
    "    model = (\n",
    "        train(\n",
    "            input_size=preprocess.outputs[\"input_size\"],\n",
    "            num_labels=preprocess.outputs[\"num_labels\"],\n",
    "            epochs=epochs,\n",
    "            train_images_prep=preprocess.outputs[\"train_images_prep\"],\n",
    "            train_labels_prep=preprocess.outputs[\"train_labels_prep\"],\n",
    "        )\n",
    "        # .set_memory_limit(\"6G\")\n",
    "        # .set_memory_request(\"6G\")\n",
    "        # .set_cpu_limit(\"1\")\n",
    "        # .set_cpu_request(\"1\")\n",
    "    )\n",
    "    model.after(preprocess)\n",
    "    evaluation = (\n",
    "        evaluate(\n",
    "            model_artifact=model.outputs[\"model_artifact\"],\n",
    "            test_images_prep=preprocess.outputs[\"test_images_prep\"],\n",
    "            test_labels_prep=preprocess.outputs[\"test_labels_prep\"],\n",
    "        )\n",
    "        .set_memory_limit(\"4G\")\n",
    "        .set_memory_request(\"4G\")\n",
    "        .set_cpu_limit(\"1\")\n",
    "        .set_cpu_request(\"1\")\n",
    "    )\n",
    "    evaluation.after(model)\n",
    "\n",
    "\n",
    "client = kfp.Client()\n",
    "client.create_run_from_pipeline_func(\n",
    "    pytorch_mnist_pipeline_v3,\n",
    "    arguments={\"epochs\": 2},\n",
    "    experiment_name=\"pytorch_mnist_pipeline_v3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b706c9b-8c1b-4db5-a0ff-6c2d48d528cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574b9ed-e34d-455c-88bf-a22fa0af6373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c117d5-b429-4ae0-908d-edf2d5986f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
